# DualPrompt-MedCap

**DualPrompt-MedCap** is a dual-prompt enhanced medical image captioning framework that integrates:

- ðŸ§  **Modality-Aware Prompting** via a semi-supervised classifier
- ðŸ§¾ **Question-Guided Clinical Prompting** via semantic understanding

These prompts are injected into the **BLIP-3** backbone for improved clinical relevance and modality alignment. A novel **ground-truth-free evaluation metric** is also provided to assess medical captions without requiring reference reports.

---

## ðŸ“ Repository Structure

```
DualPrompt-MedCap/
â”œâ”€â”€ modality_classifier/           # Semi-supervised modality classifier (used to produce prompts)
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ ablation/                  # Auxiliary experiments to compare base vs attention classifier
â”‚   â””â”€â”€ Pretrain/                  # Save the .pth file here (download link below)
â”‚
â”œâ”€â”€ dualprompt_generator/          # BLIP-3 captioning model with injected dual prompts
â”‚   â””â”€â”€ dualprompt_blip3_slake.py
â”‚
â”œâ”€â”€ gtfree_eval/                   # Ground-truth-free evaluation metrics for captions
â”‚   â””â”€â”€ evaluate_gtfree.py
â”‚
â”œâ”€â”€ baselines/                     # Baseline models for comparison
â”‚   â”œâ”€â”€ blip2/
â”‚   â”‚   â””â”€â”€ blip2_caption_rad_slake.py
â”‚   â””â”€â”€ tag2text/
â”‚       â””â”€â”€ tag2text_caption_slake_rad.py
```

---

## ðŸ”§ Key Components

### ðŸ·ï¸ Modality Classifier (`modality_classifier/`)

This classifier is trained using FixMatch with a medical attention mechanism to recognize image modality (MRI / CT / X-ray) from the [RAD dataset](https://huggingface.co/datasets/flaviagiammarino/vqa-rad). Its output is used to guide caption generation.

```bash
cd modality_classifier
python train.py
```

> ðŸ“¥ Or download pretrained model:

```bash
pip install gdown
gdown https://drive.google.com/uc?id=1--Czotnuvo003XQHik8AVI-cCWiC3exf
# Place it at: modality_classifier/Pretrain/slake_modality_model_improved.pth
```

> ðŸ”¬ **Ablation**: To compare the base FixMatch vs attention-enhanced classifier, refer to:
> ```
> modality_classifier/ablation/
> ```
> These experiments are diagnostic only and not part of the captioning pipeline.

---

### ðŸ§  Caption Generation (`dualprompt_generator/`)

Injects dual prompts into the BLIP-3 captioning pipeline:  
- **Modality Prompt** â† from classifier  
- **Question Prompt** â† via PubMedBERT semantic analysis

```bash
cd dualprompt_generator
python dualprompt_blip3_slake.py
```

---

### ðŸ“Š Ground-Truth-Free Evaluation (`gtfree_eval/`)

No-reference metric for evaluating medical captions. It assesses:
- âœ… Clinical completeness
- âœ… Anatomical structure and logic
- âœ… Visual and question relevance (via BiomedCLIP)

```bash
cd gtfree_eval
python evaluate_gtfree.py
```

---

### ðŸ§ª Baselines (`baselines/`)

Implemented for fair comparison using same datasets and settings:

| Model | Script |
|-------|--------|
| BLIP-2 | `baselines/blip2/blip2_caption_rad_slake.py` |
| Tag2Text | `baselines/tag2text/tag2text_caption_slake_rad.py` |

---

## ðŸ“¦ Installation

Install all dependencies:

```bash
pip install -r requirements.txt
```

Includes:
- `transformers==4.41.1`
- `torch==2.2.1`
- `open_clip_torch`, `einops`, `spacy`, `scispacy`, etc.

> For GT-free evaluation, install the large SciSpacy model:

```bash
python -m spacy download en_core_sci_lg
```

---

## ðŸ“‚ Datasets

| Dataset | Used For | Source |
|---------|----------|--------|
| **RAD** | Modality classifier training | [Hugging Face](https://huggingface.co/datasets/flaviagiammarino/vqa-rad) |
| **SLAKE** | Captioning + evaluation | [Hugging Face](https://huggingface.co/datasets/BoKelvin/SLAKE) |

Data loading logic is embedded inside each script.

---

## ðŸ“„ Citation

If you find this work useful, please consider citing us:

```bibtex
@inproceedings{zhao2025dualprompt,
  title     = {DualPrompt-MedCap: A Dual-Prompt Enhanced Approach for Medical Image Captioning},
  author    = {Zhao, Yining and Ali, ...},
  booktitle = {To appear},
  year      = {2025}
}
```

---

## ðŸ“¬ Contact

For questions or feedback, please open an [issue](https://github.com/Yininnnnnng/DualPrompt-MedCap/issues).
