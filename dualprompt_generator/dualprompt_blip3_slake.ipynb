{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "u52ZaG4eTJ29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aHvoD3ITJ5f",
        "outputId": "70ae991d-ea3e-405e-88ec-4aec6548e0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def extract_modality(text):\n",
        "    \"\"\"using question/answer infor to extract modality\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    modality_patterns = {\n",
        "        'mri': r'\\b(mri|magnetic resonance( imaging)?|mr imaging|nmr|magnetic resonance imaging)\\b',\n",
        "        'ct': r'\\b(ct scan|ct|computed tomography|cat scan|computerized tomography|computed axial tomography)\\b',\n",
        "        'xray': r'\\b(x-ray|xray|radiograph|radiography|chest x|cxr|roentgen|radiogram|plain film)\\b'\n",
        "    }\n",
        "\n",
        "    for modality, pattern in modality_patterns.items():\n",
        "        if re.search(pattern, text):\n",
        "            return modality\n",
        "    return None\n",
        "\n",
        "def load_rad_data(train_path, test_path):\n",
        "    \"\"\"combine\"\"\"\n",
        "    print(\"\\n=== Loading RAD Dataset ===\")\n",
        "\n",
        "    train_df = pd.read_parquet(train_path)\n",
        "    test_df = pd.read_parquet(test_path)\n",
        "\n",
        "    print(f\"Train set size: {len(train_df)}\")\n",
        "    print(f\"Test set size: {len(test_df)}\")\n",
        "\n",
        "    combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "    print(f\"Combined dataset size: {len(combined_df)}\")\n",
        "\n",
        "    print(\"\\n=== Text Analysis ===\")\n",
        "    question_lengths = combined_df['question'].str.len().describe()\n",
        "    answer_lengths = combined_df['answer'].str.len().describe()\n",
        "\n",
        "    print(\"\\nQuestion length statistics:\")\n",
        "    print(question_lengths)\n",
        "    print(\"\\nAnswer length statistics:\")\n",
        "    print(answer_lengths)\n",
        "\n",
        "    print(\"\\n=== Data Quality Check ===\")\n",
        "    null_counts = combined_df.isnull().sum()\n",
        "    print(\"\\nNull values in each column:\")\n",
        "    print(null_counts)\n",
        "\n",
        "    print(\"\\n=== Initial Modality Analysis ===\")\n",
        "    question_modalities = combined_df['question'].apply(extract_modality)\n",
        "    answer_modalities = combined_df['answer'].apply(extract_modality)\n",
        "\n",
        "    combined_modalities = question_modalities.combine_first(answer_modalities)\n",
        "    modality_counts = combined_modalities.value_counts()\n",
        "\n",
        "    print(\"\\nModality distribution in text:\")\n",
        "    print(modality_counts)\n",
        "    print(\"\\nPercentage of samples with modality information:\")\n",
        "    print(f\"{(len(combined_modalities.dropna()) / len(combined_df)) * 100:.2f}%\")\n",
        "\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "h802tNqoTJ9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MedicalModalityAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.anatomy_attention = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels//2, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm2d(in_channels//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels//2, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "        self.texture_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels//16, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels//16, in_channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "        self.multi_scale = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels, in_channels//4, 3, padding=1, dilation=1),\n",
        "            nn.Conv2d(in_channels, in_channels//4, 3, padding=2, dilation=2),\n",
        "            nn.Conv2d(in_channels, in_channels//4, 3, padding=4, dilation=4)\n",
        "        ])\n",
        "\n",
        "        self.channel_adjust = nn.Conv2d(in_channels//4*3, in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        anatomy_weight = self.anatomy_attention(x)\n",
        "        texture_weight = self.texture_attention(x)\n",
        "\n",
        "        multi_scale_features = []\n",
        "        for conv in self.multi_scale:\n",
        "            multi_scale_features.append(conv(x))\n",
        "        multi_scale_feat = torch.cat(multi_scale_features, dim=1)\n",
        "        multi_scale_feat = self.channel_adjust(multi_scale_feat)\n",
        "\n",
        "        enhanced = x * anatomy_weight * texture_weight\n",
        "        return enhanced + multi_scale_feat\n",
        "\n",
        "class ModalityClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        self.attention1 = MedicalModalityAttention(256)\n",
        "        self.attention2 = MedicalModalityAttention(512)\n",
        "        self.attention3 = MedicalModalityAttention(1024)\n",
        "        self.attention4 = MedicalModalityAttention(2048)\n",
        "\n",
        "        in_features = self.backbone.fc.in_features\n",
        "        self.modality_head = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.attention1(self.backbone.layer1(x))\n",
        "        x = self.attention2(self.backbone.layer2(x))\n",
        "        x = self.attention3(self.backbone.layer3(x))\n",
        "        x = self.attention4(self.backbone.layer4(x))\n",
        "\n",
        "        x = self.backbone.avgpool(x)\n",
        "        features = torch.flatten(x, 1)\n",
        "\n",
        "        return self.modality_head(features)\n",
        "\n",
        "# data augmentation\n",
        "class MedicalImageAugmentation:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.base_aug = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.RandomAffine(\n",
        "                degrees=0,\n",
        "                translate=(0.1, 0.1),\n",
        "                scale=(0.9, 1.1)\n",
        "            ),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.mri_aug = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.RandomAffine(\n",
        "                degrees=0,\n",
        "                translate=(0.15, 0.15),\n",
        "                scale=(0.85, 1.15)\n",
        "            ),\n",
        "            transforms.ColorJitter(\n",
        "                brightness=0.3,\n",
        "                contrast=0.3,\n",
        "                saturation=0.2,\n",
        "                hue=0.1\n",
        "            ),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.test_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "        ])"
      ],
      "metadata": {
        "id": "SNFcnhVoTJ-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RADDataset(Dataset):\n",
        "    def __init__(self, df, is_labeled=True, mode='train'):\n",
        "        self.df = df\n",
        "        self.is_labeled = is_labeled\n",
        "        self.mode = mode\n",
        "        self.augmentation = MedicalImageAugmentation()\n",
        "\n",
        "        self.valid_samples = []\n",
        "        self.unlabeled_samples = []\n",
        "\n",
        "        self.modality_to_idx = {\n",
        "            'mri': 0,\n",
        "            'ct': 1,\n",
        "            'xray': 2\n",
        "        }\n",
        "\n",
        "        print(\"\\n=== Dataset Statistics ===\")\n",
        "        total_samples = len(df)\n",
        "        valid_count = 0\n",
        "        modality_counts = {'mri': 0, 'ct': 0, 'xray': 0}\n",
        "\n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "            question_modality = extract_modality(row['question'])\n",
        "            answer_modality = extract_modality(row['answer'])\n",
        "\n",
        "            modality = question_modality or answer_modality\n",
        "\n",
        "            if modality in ['mri', 'ct', 'xray']:\n",
        "                self.valid_samples.append({\n",
        "                    'image': row['image'],\n",
        "                    'modality': modality,\n",
        "                    'index': idx\n",
        "                })\n",
        "                modality_counts[modality] += 1\n",
        "                valid_count += 1\n",
        "            else:\n",
        "                self.unlabeled_samples.append({\n",
        "                    'image': row['image'],\n",
        "                    'index': idx\n",
        "                })\n",
        "\n",
        "        if self.is_labeled:\n",
        "            print(f\"\\nTotal samples: {total_samples}\")\n",
        "            print(f\"Labeled samples: {valid_count} ({valid_count/total_samples*100:.2f}%)\")\n",
        "            print(f\"Unlabeled samples: {total_samples - valid_count} ({(total_samples-valid_count)/total_samples*100:.2f}%)\")\n",
        "\n",
        "            print(\"\\n=== Class Distribution ===\")\n",
        "            for modality, count in modality_counts.items():\n",
        "                print(f\"{modality.upper()}: {count} samples ({count/valid_count*100:.2f}%)\")\n",
        "\n",
        "    def decode_image(self, image_data):\n",
        "        try:\n",
        "            if isinstance(image_data, dict):\n",
        "                if 'bytes' in image_data:\n",
        "                    bytes_data = image_data['bytes']\n",
        "                    if isinstance(bytes_data, str):\n",
        "                        bytes_data = bytes_data.encode('latin1')\n",
        "                    img = Image.open(io.BytesIO(bytes_data))\n",
        "                    return np.array(img)\n",
        "                elif 'array' in image_data:\n",
        "                    return np.array(image_data['array'])\n",
        "            return np.array(image_data)\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError decoding image:\")\n",
        "            print(f\"Image data type: {type(image_data)}\")\n",
        "            if isinstance(image_data, dict):\n",
        "                print(f\"Dict keys: {image_data.keys()}\")\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.is_labeled:\n",
        "            return len(self.valid_samples)\n",
        "        return len(self.unlabeled_samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_labeled:\n",
        "            sample = self.valid_samples[idx]\n",
        "            image_data = sample['image']\n",
        "            label = self.modality_to_idx[sample['modality']]\n",
        "\n",
        "\n",
        "            if self.mode == 'train':\n",
        "                if sample['modality'] == 'mri':\n",
        "                    image_tensor = self._process_image(image_data, aug_type='mri')\n",
        "                else:\n",
        "                    image_tensor = self._process_image(image_data, aug_type='base')\n",
        "            else:\n",
        "                image_tensor = self._process_image(image_data, aug_type='test')\n",
        "\n",
        "            return image_tensor, label\n",
        "        else:\n",
        "            sample = self.unlabeled_samples[idx]\n",
        "            image_data = sample['image']\n",
        "\n",
        "            weak_aug = self._process_image(image_data, aug_type='base')\n",
        "            strong_aug = self._process_image(image_data, aug_type='mri')\n",
        "\n",
        "            return weak_aug, strong_aug\n",
        "\n",
        "    def _process_image(self, image_data, aug_type='base'):\n",
        "        try:\n",
        "            image_array = self.decode_image(image_data)\n",
        "\n",
        "            if len(image_array.shape) == 2:\n",
        "                image_array = np.stack([image_array] * 3, axis=-1)\n",
        "            elif len(image_array.shape) == 3 and image_array.shape[2] == 4:\n",
        "                image_array = image_array[:, :, :3]\n",
        "\n",
        "            image = Image.fromarray(image_array.astype('uint8'))\n",
        "\n",
        "            if aug_type == 'mri':\n",
        "                return self.augmentation.mri_aug(image)\n",
        "            elif aug_type == 'test':\n",
        "                return self.augmentation.test_transform(image)\n",
        "            else:\n",
        "                return self.augmentation.base_aug(image)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing image:\")\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "EZ1nTaU4TJ_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train & val\n",
        "def train_epoch(model, train_loader, unlabeled_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    unlabeled_iter = iter(unlabeled_loader)\n",
        "\n",
        "    pbar = tqdm(train_loader, desc='Training')\n",
        "    for batch_idx, (inputs, labels) in enumerate(pbar):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        try:\n",
        "            unlabeled_weak, unlabeled_strong = next(unlabeled_iter)\n",
        "        except StopIteration:\n",
        "            unlabeled_iter = iter(unlabeled_loader)\n",
        "            unlabeled_weak, unlabeled_strong = next(unlabeled_iter)\n",
        "\n",
        "        unlabeled_weak = unlabeled_weak.to(device)\n",
        "        unlabeled_strong = unlabeled_strong.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pseudo_outputs = model(unlabeled_weak)\n",
        "            pseudo_probs = F.softmax(pseudo_outputs, dim=1)\n",
        "            max_probs, pseudo_labels = torch.max(pseudo_probs, dim=1)\n",
        "            mask = max_probs.ge(0.95)\n",
        "\n",
        "        strong_outputs = model(unlabeled_strong)\n",
        "\n",
        "        sup_loss = criterion(outputs, labels)\n",
        "        unsup_loss = (F.cross_entropy(strong_outputs, pseudo_labels,\n",
        "                                    reduction='none') * mask).mean()\n",
        "\n",
        "        loss = sup_loss + 0.5 * unsup_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{total_loss/(batch_idx+1):.3f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "\n",
        "    return total_loss / len(train_loader), correct / total\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc='Evaluating'):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    classification_metrics = classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        target_names=['mri', 'ct', 'xray'],\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    return (total_loss / len(test_loader),\n",
        "            correct / total,\n",
        "            classification_metrics,\n",
        "            all_preds,\n",
        "            all_labels)\n",
        "\n",
        "def plot_training_history(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    ax1.plot(history['train_loss'], label='Train Loss')\n",
        "    ax1.plot(history['val_loss'], label='Val Loss')\n",
        "    ax1.set_title('Loss History')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(history['train_acc'], label='Train Acc')\n",
        "    ax2.plot(history['val_acc'], label='Val Acc')\n",
        "    ax2.set_title('Accuracy History')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['MRI', 'CT', 'X-ray'],\n",
        "                yticklabels=['MRI', 'CT', 'X-ray'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "atQ_5OVFTKBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_model():\n",
        "    set_seed(42)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    print(\"\\nLoading RAD dataset...\")\n",
        "    train_path = '/content/drive/MyDrive/RADdataset/train-00000-of-00001-eb8844602202be60.parquet'\n",
        "    test_path = '/content/drive/MyDrive/RADdataset/test-00000-of-00001-e5bc3d208bb4deeb.parquet'\n",
        "    rad_df = pd.read_parquet(train_path)\n",
        "    test_df = pd.read_parquet(test_path)\n",
        "    combined_df = pd.concat([rad_df, test_df], ignore_index=True)\n",
        "\n",
        "\n",
        "    labeled_dataset = RADDataset(combined_df, is_labeled=True, mode='train')\n",
        "    unlabeled_dataset = RADDataset(combined_df, is_labeled=False)\n",
        "    test_dataset = RADDataset(combined_df, is_labeled=True, mode='test')\n",
        "\n",
        "    # split train & val\n",
        "    total_size = len(labeled_dataset)\n",
        "    train_size = int(0.8 * total_size)\n",
        "    val_size = total_size - train_size\n",
        "    train_dataset, val_dataset = random_split(labeled_dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "    batch_size = 8\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    unlabeled_loader = DataLoader(\n",
        "        unlabeled_dataset,\n",
        "        batch_size=batch_size*2,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "\n",
        "    model = ModalityClassifier(num_classes=3)\n",
        "    model_path = '/content/drive/MyDrive/modelparasave/slake_modality_model_improved.pth'\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Loading pretrained model from {model_path}\")\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(\"Pretrained model loaded successfully\")\n",
        "    else:\n",
        "        print(\"No pretrained model found, starting from scratch\")\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    class_weights = torch.FloatTensor([1.5, 1.0, 1.0]).to(device)  # MRI weight\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "\n",
        "    optimizer = optim.AdamW([\n",
        "        {'params': model.backbone.parameters(), 'lr': 1e-5},\n",
        "        {'params': model.attention1.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.attention2.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.attention3.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.attention4.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.modality_head.parameters(), 'lr': 1e-4}\n",
        "    ], weight_decay=0.01)\n",
        "\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': [],\n",
        "        'modality_metrics': []\n",
        "    }\n",
        "\n",
        "    # begin training\n",
        "    num_epochs = 10\n",
        "    best_acc = 0\n",
        "    print(\"\\nStarting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # train\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            model, train_loader, unlabeled_loader, criterion, optimizer, device\n",
        "        )\n",
        "\n",
        "        # val\n",
        "        val_loss, val_acc, metrics, val_preds, val_labels = evaluate(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # update\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['modality_metrics'].append(metrics)\n",
        "\n",
        "        # print epoches\n",
        "        print(f\"\\nTraining Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "        print(\"\\nDetailed metrics for each modality:\")\n",
        "        for modality in ['mri', 'ct', 'xray']:\n",
        "            print(f\"{modality}:\")\n",
        "            print(f\"  Precision: {metrics[modality]['precision']:.4f}\")\n",
        "            print(f\"  Recall: {metrics[modality]['recall']:.4f}\")\n",
        "            print(f\"  F1-score: {metrics[modality]['f1-score']:.4f}\")\n",
        "\n",
        "        # save best model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            print(f\"\\nSaving new best model with validation accuracy: {best_acc:.4f}\")\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'best_acc': best_acc,\n",
        "                'history': history\n",
        "            }, model_path)\n",
        "\n",
        "\n",
        "        plot_confusion_matrix(val_labels, val_preds)\n",
        "\n",
        "\n",
        "    plot_training_history(history)\n",
        "\n",
        "    print(\"\\nTraining completed!\")\n",
        "    print(f\"Best validation accuracy: {best_acc:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    finetune_model()"
      ],
      "metadata": {
        "id": "GI223S9YTKEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4W_Ox7DfHaQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAmuyiFFHaSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
