{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9j3AIp3FChqU"
      },
      "outputs": [],
      "source": [
        "#==============blip2 with SLAKE================"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import io\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import traceback\n",
        "\n",
        "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
        "\n",
        "global_models = {}"
      ],
      "metadata": {
        "id": "EDoygvxumIvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d46dd4-1a6f-4b6d-abcd-5f22ebe69a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_models():\n",
        "    if 'blip2' not in global_models:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "        print(\"Loading BLIP-2 model...\")\n",
        "\n",
        "        processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
        "        model = Blip2ForConditionalGeneration.from_pretrained(\n",
        "            \"Salesforce/blip2-opt-2.7b\",\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        global_models['processor'] = processor\n",
        "        global_models['model'] = model\n",
        "        global_models['device'] = device\n",
        "\n",
        "        print(\"BLIP-2 model loaded successfully\")\n",
        "\n",
        "def process_image_with_blip2(image_path, prompt=\"\"):\n",
        "    try:\n",
        "        print(f\"Loading image from: {image_path}\")\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"ERROR: Image file not found: {image_path}\")\n",
        "            return \"Error: Image file not found\"\n",
        "\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        print(f\"Image successfully loaded. Size: {image.size}\")\n",
        "\n",
        "\n",
        "        print(\"Processing image with BLIP-2...\")\n",
        "        processor = global_models['processor']\n",
        "        model = global_models['model']\n",
        "\n",
        "        inputs = processor(images=image, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "\n",
        "        print(\"Generating description...\")\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=100,\n",
        "                num_beams=5,\n",
        "                min_length=20,\n",
        "                top_p=0.9,\n",
        "                repetition_penalty=1.5,\n",
        "                length_penalty=1.0,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "\n",
        "        caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "        if prompt:\n",
        "            medical_caption = f\"{prompt} {caption}\"\n",
        "            print(f\"Generated caption: {medical_caption}\")\n",
        "            return medical_caption\n",
        "        else:\n",
        "            print(f\"Generated caption: {caption}\")\n",
        "            return caption\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        print(traceback.format_exc())\n",
        "        return f\"Error generating caption: {str(e)}\"\n",
        "\n",
        "def main():\n",
        "\n",
        "    load_models()\n",
        "\n",
        "\n",
        "    slake_base_dir = '/content/drive/MyDrive/PhD/Research1/slakedataset/Slake1.0'\n",
        "    json_path = os.path.join(slake_base_dir, 'test.json')\n",
        "    output_dir = '/content/drive/MyDrive/PhD/Research1/output'\n",
        "    output_json = os.path.join(output_dir, 'slake_blip2_results.json')\n",
        "\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "\n",
        "    english_samples = [item for item in data if item.get('q_lang') == 'en']\n",
        "    print(f\"Loaded {len(english_samples)} English samples from test.json\")\n",
        "\n",
        "\n",
        "    modality_counts = {}\n",
        "    for item in english_samples:\n",
        "        modality = item.get('modality', 'Unknown')\n",
        "        modality_counts[modality] = modality_counts.get(modality, 0) + 1\n",
        "\n",
        "    print(\"Modality distribution:\")\n",
        "    for modality, count in modality_counts.items():\n",
        "        print(f\"  {modality}: {count} samples\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "\n",
        "    temp_output_json = os.path.join(output_dir, 'slake_blip2_results_temp.json')\n",
        "\n",
        "\n",
        "    for idx, sample in tqdm(enumerate(english_samples), total=len(english_samples), desc=\"Processing images\"):\n",
        "        img_name = sample.get('img_name', '')\n",
        "        img_id = sample.get('img_id', '')\n",
        "        question = sample.get('question', '')\n",
        "        answer = sample.get('answer', '')\n",
        "        modality = sample.get('modality', '')\n",
        "\n",
        "\n",
        "        img_path = os.path.join(slake_base_dir, 'imgs', img_name)\n",
        "\n",
        "        print(f\"\\nProcessing image {idx} (ID: {img_id})\")\n",
        "        print(f\"Image path: {img_path}\")\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Modality: {modality}\")\n",
        "\n",
        "        try:\n",
        "\n",
        "            if not os.path.exists(img_path):\n",
        "                print(f\"WARNING: Image file not found at {img_path}\")\n",
        "\n",
        "                alternative_paths = [\n",
        "                    os.path.join(slake_base_dir, 'img', img_name),\n",
        "                    os.path.join(slake_base_dir, 'images', img_name)\n",
        "                ]\n",
        "                for alt_path in alternative_paths:\n",
        "                    if os.path.exists(alt_path):\n",
        "                        img_path = alt_path\n",
        "                        print(f\"Found image at alternative path: {img_path}\")\n",
        "                        break\n",
        "\n",
        "\n",
        "            prompt = \"\"\n",
        "            caption_prefix = \"\"\n",
        "            if modality == \"CT\":\n",
        "                caption_prefix = \"This CT scan shows\"\n",
        "            elif modality == \"MRI\":\n",
        "                caption_prefix = \"This MRI scan reveals\"\n",
        "            elif modality == \"X-ray\":\n",
        "                caption_prefix = \"This X-ray image displays\"\n",
        "            else:\n",
        "                caption_prefix = \"This medical image shows\"\n",
        "\n",
        "\n",
        "            blip2_caption = process_image_with_blip2(img_path)\n",
        "\n",
        "\n",
        "            if not blip2_caption.lower().startswith(\"this\"):\n",
        "                blip2_caption = f\"{caption_prefix} {blip2_caption}\"\n",
        "\n",
        "\n",
        "            result = {\n",
        "                \"id\": idx,\n",
        "                \"img_id\": img_id,\n",
        "                \"img_name\": img_name,\n",
        "                \"question\": question,\n",
        "                \"original_answer\": answer,\n",
        "                \"modality\": modality,\n",
        "                \"blip2_caption\": blip2_caption\n",
        "            }\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sample {idx}, image {img_name}: {e}\")\n",
        "            print(traceback.format_exc())\n",
        "\n",
        "            results.append({\n",
        "                \"id\": idx,\n",
        "                \"img_id\": img_id,\n",
        "                \"img_name\": img_name,\n",
        "                \"question\": question,\n",
        "                \"original_answer\": answer,\n",
        "                \"modality\": modality,\n",
        "                \"blip2_caption\": f\"Error generating caption: {str(e)}\"\n",
        "            })\n",
        "\n",
        "\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            try:\n",
        "                with open(temp_output_json, 'w') as f:\n",
        "                    json.dump(results, f, indent=2)\n",
        "                print(f\"Temporary results saved to {temp_output_json} after processing {idx+1} samples\")\n",
        "            except Exception as save_error:\n",
        "                print(f\"Error saving temporary results: {save_error}\")\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "\n",
        "    try:\n",
        "        with open(output_json, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        print(f\"Processing complete. Results saved to {output_json}\")\n",
        "    except Exception as save_error:\n",
        "        print(f\"Error saving final results: {save_error}\")\n",
        "\n",
        "        backup_output = os.path.join('/content', 'slake_blip2_results_backup.json')\n",
        "        with open(backup_output, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        print(f\"Results saved to backup location: {backup_output}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "IvPTHsHgmHnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_wvwN7kdmHp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}